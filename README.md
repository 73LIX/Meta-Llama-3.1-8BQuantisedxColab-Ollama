# Meta-Llama-3.1-8BQuantisedxColab-Ollama

Meta Llama 3.1 is the latest open source LLM released by meta. It supports 8 Languages `English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai`. Here you can run the model for free in Quantized form provided by `Ollama` on the `T4 Gpu` of google colab.

The **Quantized**üéØ form is basically smaller in size then the original model, which saves your disk space, internet and also has faster inferences.
Q4 quantisation is used here in this notebook. You can switch it to q8 by changing the download link in Download model cell.

NOTE: This colab notebook performs better than the Llama 3.1-8B_Colab notebook, in terms of inference speed and model size. And you are free from that hugging face access and token hassle.

‚ùóQuantisation can reduce the performance of the model in some use case for example it can make mistakes or create halluciantion, so always check for important info. So if you have the model access on hugging face and also if you have the pro version of google colab then you can also use the Llama 3.1-8B_Colab notebook.

| |Google Colab|GitHub|
|:--|:-:|:-:|
| üåü **Llama 3.1-8B_QuantisedxOllama** |  [![Open in Colab](https://github.com/73LIX/Meta-Llama-3.1-8BxColab/blob/main/asset/colab_logo.svg)](https://colab.research.google.com/drive/1S9q6cvH8y2WMml7pczg0Bl-VS6Le-jzZ?usp=sharing)
| ‚≠ê **Llama 3.1-8B_Colab** | [![Open in Colab](https://github.com/73LIX/Meta-Llama-3.1-8BxColab/blob/main/asset/colab_logo.svg)](https://colab.research.google.com/drive/10c_GQ8wqVXuX5JciX0gHVstO0WHaUbqD?usp=sharing ) | [![GitHub](https://github.com/73LIX/Meta-Llama-3.1-8BQuantisedxColab-Ollama/blob/main/assets/github.svg)](https://github.com/73LIX/Meta-Llama-3.1-8BxColab.git)

